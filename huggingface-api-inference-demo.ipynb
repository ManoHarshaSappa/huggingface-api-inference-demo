{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec520dff-c0cf-4b70-9d57-91b00abc16b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.50.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7f4f2d7-5e72-4f9e-b1f3-bf6318c5a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b30ec2-249a-472d-8714-babb99d9ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at openai-community/roberta-base-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model from Hugging Face\n",
    "model_name = \"openai-community/roberta-base-openai-detector\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c5e24f6-dc57-49f5-8973-d7b457be56c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at openai-community/roberta-base-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Imports\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Step 2: Load tokenizer and model\n",
    "model_name = \"openai-community/roberta-base-openai-detector\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Step 3: Device setup (CPU or MPS for Mac)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Step 4: Prediction function\n",
    "def predict_text_class(text):\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred_class].item()\n",
    "\n",
    "    # Map labels (same as your project)\n",
    "    label_map = {\n",
    "        0: \"Human-Generated\",\n",
    "        1: \"AI-Generated\"\n",
    "    }\n",
    "\n",
    "    print(f\" Prediction: {label_map[pred_class]} (confidence: {confidence:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69a4911c-2448-4ffd-a442-9ffad0a09563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediction: AI-Generated (confidence: 0.67)\n",
      " Prediction: AI-Generated (confidence: 0.75)\n",
      " Prediction: AI-Generated (confidence: 1.00)\n",
      " Prediction: AI-Generated (confidence: 0.65)\n",
      " Prediction: AI-Generated (confidence: 0.98)\n"
     ]
    }
   ],
   "source": [
    "predict_text_class(\"I grabbed a coffee, walked around the block, and felt way better after that.\") \n",
    "predict_text_class(\"I just started journaling, and it’s surprisingly therapeutic.\")\n",
    "predict_text_class(\"Cooked dinner for the family today and didn’t burn anything. Proud moment!\")\n",
    "predict_text_class(\"My dog literally understands everything I say, I swear.\")\n",
    "predict_text_class(\"Got stuck in traffic for 2 hours and missed my class—ugh!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17ee4594-7bb5-45ca-96dd-3fd5370d0c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediction: Human-Generated (confidence: 0.74)\n",
      " Prediction: Human-Generated (confidence: 0.84)\n",
      " Prediction: Human-Generated (confidence: 0.89)\n",
      " Prediction: Human-Generated (confidence: 0.64)\n",
      " Prediction: Human-Generated (confidence: 0.94)\n",
      " Prediction: Human-Generated (confidence: 0.59)\n",
      " Prediction: Human-Generated (confidence: 0.62)\n"
     ]
    }
   ],
   "source": [
    "predict_text_class(\"Guess what? I finally submitted the assignment at 11:58 PM\")\n",
    "predict_text_class(\"Maaaann that movie ending hit different... I’m not okay\")\n",
    "predict_text_class(\"Tell me why I walked into the room and forgot what I needed\")\n",
    "predict_text_class(\"I swear my brain just randomly decides to stop functioning after 8pm\")\n",
    "predict_text_class(\"My mom really just called me lazy while I’m on my third breakdown this week\")\n",
    "predict_text_class(\"Me: gonna be productive today. Also me: *watches 6 hours of YouTube\")\n",
    "predict_text_class(\"I texted them first... again. I'm retiring from this friendship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6928ca1a-030e-40fc-8e76-ba0e4a2b16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing with my model its givin accurate results...\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "\n",
    "load_path = \"saved_bert_model\" \n",
    "tokenizer = BertTokenizer.from_pretrained(load_path)\n",
    "model = BertForSequenceClassification.from_pretrained(load_path)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def predict_from_saved_model(text):\n",
    "    model.eval() \n",
    "    encoded_input = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "    encoded_input = {key: val.to(device) for key, val in encoded_input.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred].item()\n",
    "\n",
    "    label = \"AI-Generated\" if pred == 1 else \"Human-Generated\"\n",
    "    return f\" Prediction: {label} (confidence: {confidence:.2f})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84467702-1a09-4b19-bcdf-956238392278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediction: AI-Generated (confidence: 0.68)\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"This essay provides an in-depth analysis of renewable energy sources.\"\n",
    "print(predict_from_saved_model(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d68be435-a0d7-4dec-b59e-0d75ec11cc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:  Prediction: Human-Generated (confidence: 0.70)\n",
      "Sample 2:  Prediction: Human-Generated (confidence: 0.71)\n",
      "Sample 3:  Prediction: Human-Generated (confidence: 0.52)\n",
      "Sample 4:  Prediction: Human-Generated (confidence: 0.72)\n",
      "Sample 5:  Prediction: Human-Generated (confidence: 0.66)\n",
      "Sample 6:  Prediction: Human-Generated (confidence: 0.55)\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"Guess what? I finally submitted the assignment at 11:58 PM\",\n",
    "    \"Maaaann that movie ending hit different... I’m not okay\",\n",
    "    \"Tell me why I walked into the room and forgot what I needed \",\n",
    "    \"I swear my brain just randomly decides to stop functioning after 8pm\",\n",
    "    \"My mom really just called me lazy while I’m on my third breakdown this week\",\n",
    "    \"I texted them first... again. I'm retiring from this friendship\"\n",
    "]\n",
    "\n",
    "# Run predictions\n",
    "for i, text in enumerate(samples, 1):\n",
    "    print(f\"Sample {i}: {predict_from_saved_model(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ecbfc-52a7-411c-bf3b-a7f556775134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
